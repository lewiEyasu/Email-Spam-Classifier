{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-17T13:59:37.626900Z","iopub.execute_input":"2022-07-17T13:59:37.627304Z","iopub.status.idle":"2022-07-17T13:59:37.643718Z","shell.execute_reply.started":"2022-07-17T13:59:37.627263Z","shell.execute_reply":"2022-07-17T13:59:37.642585Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n#import tensorflow_text as text\nimport numpy as np\nimport re","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:59:37.646915Z","iopub.execute_input":"2022-07-17T13:59:37.647678Z","iopub.status.idle":"2022-07-17T13:59:37.653656Z","shell.execute_reply.started":"2022-07-17T13:59:37.647633Z","shell.execute_reply":"2022-07-17T13:59:37.652527Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"<h2>Load the email spam dataset</h2> ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nurl = \"/kaggle/input/email-spam-dataset/enronSpamSubset.csv\"\n\ndf = pd.read_csv(url)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:59:37.655116Z","iopub.execute_input":"2022-07-17T13:59:37.655702Z","iopub.status.idle":"2022-07-17T13:59:37.828171Z","shell.execute_reply.started":"2022-07-17T13:59:37.655667Z","shell.execute_reply":"2022-07-17T13:59:37.827022Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<h2>Clean the email spam dataset</h2>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"dataset = df[['Body', 'Label']]\ndataset. dropna() \ndataset[dataset[\"Label\"] == 0].shape","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:59:37.830538Z","iopub.execute_input":"2022-07-17T13:59:37.830880Z","iopub.status.idle":"2022-07-17T13:59:37.848508Z","shell.execute_reply.started":"2022-07-17T13:59:37.830848Z","shell.execute_reply":"2022-07-17T13:59:37.847449Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"dataset['Body'] = dataset['Body'].apply (lambda x: \" \".join (x.lower () for x in x.split ()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['Body'] = dataset['Body'].str.replace (r\"\"\"[^\\w\\s]+\"\"\",\"\", regex = True)\n\nsample_dataset = dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n\n\nnltk.download(\"stopwords\")\n# remove stop words\nstop = stopwords.words ('english')\nsample_dataset['Body']= sample_dataset['Body'].apply (lambda x: \" \".join (x for x in x.split () if x not in stopwords.words(\"english\")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2> Split the dataset </h2>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(sample_dataset['Body'],sample_dataset['Label'],stratify=sample_dataset['Label'])\n#print(x_train.shape,y_train.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:15:24.743064Z","iopub.execute_input":"2022-07-17T14:15:24.744610Z","iopub.status.idle":"2022-07-17T14:15:24.762070Z","shell.execute_reply.started":"2022-07-17T14:15:24.744557Z","shell.execute_reply":"2022-07-17T14:15:24.760953Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import collections\n\nimport pandas as pd \nimport numpy as np\nimport json\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:09:27.101748Z","iopub.execute_input":"2022-07-17T14:09:27.102939Z","iopub.status.idle":"2022-07-17T14:09:27.108418Z","shell.execute_reply.started":"2022-07-17T14:09:27.102900Z","shell.execute_reply":"2022-07-17T14:09:27.107125Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"<h2>Applying Event models for text classification </h2>","metadata":{}},{"cell_type":"code","source":"def get_words(message):\n    '''\n     Args:\n        message: A string containing an SMS message\n\n    Returns:\n       The list of normalized words from the message.\n    \n    '''\n    return message.lower().split()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:10:10.325074Z","iopub.execute_input":"2022-07-17T14:10:10.325429Z","iopub.status.idle":"2022-07-17T14:10:10.331080Z","shell.execute_reply.started":"2022-07-17T14:10:10.325401Z","shell.execute_reply":"2022-07-17T14:10:10.329683Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def create_dictionary(messages):\n    \n    '''\n    Args:\n        messages: A List containing an SMS messages\n\n    Returns:\n       create a dictionary from the messages.\n    \n    '''\n    words = [ word for message in messages for word in get_words(message)]\n    \n    word_and_count = collections.Counter(words)\n    \n    freq_words = [ word for word, count in word_and_count.items() if count >= 5 ]\n    \n    dictionary = { word: index for index, word in enumerate(freq_words) }\n    \n    return dictionary\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:10:21.361730Z","iopub.execute_input":"2022-07-17T14:10:21.362139Z","iopub.status.idle":"2022-07-17T14:10:21.369542Z","shell.execute_reply.started":"2022-07-17T14:10:21.362106Z","shell.execute_reply":"2022-07-17T14:10:21.368389Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def encode_text(messages, dictionary):\n    \n    '''\n    Args:\n        messages: A List containing an SMS messages\n        dictionary: A list of word in form in dictionary\n\n    Returns:\n       encode the messages refeing to the dictionary \n    \n    '''\n    m, n = len(messages), len(dictionary)\n    words_count = [ collections.Counter(get_words(message)) for message in messages ]\n    encode_text_matrix = np.zeros((m,n) , dtype=int)\n    \n    for i in range(m):\n        for word, count in words_count[i].items():\n            if word in dictionary:\n                encode_text_matrix[i][dictionary[word]] += count\n                \n            \n    return encode_text_matrix    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:10:37.676420Z","iopub.execute_input":"2022-07-17T14:10:37.676805Z","iopub.status.idle":"2022-07-17T14:10:37.685096Z","shell.execute_reply.started":"2022-07-17T14:10:37.676770Z","shell.execute_reply":"2022-07-17T14:10:37.683947Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def naive_bayes_model(matrix, y):\n    \n    m, n = matrix.shape\n    phi_y = np.mean(y)\n    phi_k_y1 = (1 + matrix[y==1].sum(axis=0)) / (n + matrix[y == 1].sum())\n    phi_k_y0 = (1 + matrix[y==0].sum(axis=0)) / (n + matrix[y == 0].sum())\n    return phi_y, phi_k_y1, phi_k_y0\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:17:47.971735Z","iopub.execute_input":"2022-07-17T14:17:47.972119Z","iopub.status.idle":"2022-07-17T14:17:47.979372Z","shell.execute_reply.started":"2022-07-17T14:17:47.972088Z","shell.execute_reply":"2022-07-17T14:17:47.978462Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def predict_from_naive_bayes_model(model, matrix):\n    \n     phi_y, phi_k_y1, phi_k_y0 = model\n     \n     return matrix.dot (np.log(phi_k_y1) - np.log(phi_k_y0)) + np.log(phi_y / (1 - phi_y)) >= 0\n   \n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:11:02.389970Z","iopub.execute_input":"2022-07-17T14:11:02.390354Z","iopub.status.idle":"2022-07-17T14:11:02.396394Z","shell.execute_reply.started":"2022-07-17T14:11:02.390322Z","shell.execute_reply":"2022-07-17T14:11:02.395540Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"<h2>Train the model </h2>","metadata":{}},{"cell_type":"code","source":"dictionary = create_dictionary(x_train)\ntrain_matrix = encode_text(x_train, dictionary)\ntest_matrix = encode_text(x_test, dictionary)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:15:34.316802Z","iopub.execute_input":"2022-07-17T14:15:34.317239Z","iopub.status.idle":"2022-07-17T14:15:38.276030Z","shell.execute_reply.started":"2022-07-17T14:15:34.317205Z","shell.execute_reply":"2022-07-17T14:15:38.275027Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"naive_model = naive_bayes_model(train_matrix, y_train)\nphi_y, phi_k_y1, phi_k_y0 = naive_model\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:17:52.286095Z","iopub.execute_input":"2022-07-17T14:17:52.286512Z","iopub.status.idle":"2022-07-17T14:17:53.112291Z","shell.execute_reply.started":"2022-07-17T14:17:52.286462Z","shell.execute_reply":"2022-07-17T14:17:53.111096Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"'''\nmodel_spam = {\n    'dictionary': dictionary,\n    'phi_y': phi_y,\n    'phi_k_y1': phi_k_y1.tolist(), \n    'phi_k_y0': phi_k_y0.tolist(),\n    \n}\nwith open ('spam_classifier.json', 'w') as f:\n    json.dump(model_spam, f)\n'''\n\n\nnaive_bayes_predictions = predict_from_naive_bayes_model(naive_model, test_matrix)\nnaive_bayes_accuracy = np.mean(naive_bayes_predictions == y_test)\nprint(naive_bayes_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:19:25.762576Z","iopub.execute_input":"2022-07-17T14:19:25.763511Z","iopub.status.idle":"2022-07-17T14:19:25.976792Z","shell.execute_reply.started":"2022-07-17T14:19:25.763438Z","shell.execute_reply":"2022-07-17T14:19:25.972533Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nfrom matplotlib import pyplot as plt\nimport seaborn as sn\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:54:13.875401Z","iopub.execute_input":"2022-07-17T14:54:13.875972Z","iopub.status.idle":"2022-07-17T14:54:13.889304Z","shell.execute_reply.started":"2022-07-17T14:54:13.875925Z","shell.execute_reply":"2022-07-17T14:54:13.888187Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def confusion_Matrix(y_test,y_predic):\n    cm = confusion_matrix(y_test, y_predic)\n    cm \n    sn.heatmap(cm, annot=True, fmt='d')\n    plt.xlabel('Predicted')\n    plt.ylabel('Truth')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:59:26.769301Z","iopub.execute_input":"2022-07-17T14:59:26.770142Z","iopub.status.idle":"2022-07-17T14:59:26.775783Z","shell.execute_reply.started":"2022-07-17T14:59:26.770102Z","shell.execute_reply":"2022-07-17T14:59:26.774799Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"confusion_Matrix(y_test,naive_bayes_predictions)\nprint(classification_report(y_test, naive_bayes_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:01:54.979502Z","iopub.execute_input":"2022-07-17T15:01:54.979927Z","iopub.status.idle":"2022-07-17T15:01:55.213455Z","shell.execute_reply.started":"2022-07-17T15:01:54.979895Z","shell.execute_reply":"2022-07-17T15:01:55.212169Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"<h2>Compare the naive_model with a LogisticRegression","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support\nprecision_recall_fscore_support(y_test,naive_bayes_predictions,average='macro')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:22:32.278495Z","iopub.execute_input":"2022-07-17T14:22:32.279507Z","iopub.status.idle":"2022-07-17T14:22:32.289374Z","shell.execute_reply.started":"2022-07-17T14:22:32.279442Z","shell.execute_reply":"2022-07-17T14:22:32.288238Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogisticRegr = LogisticRegression()\nlogisticRegr.fit(train_matrix, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:00:44.294327Z","iopub.execute_input":"2022-07-17T15:00:44.295398Z","iopub.status.idle":"2022-07-17T15:01:08.760255Z","shell.execute_reply.started":"2022-07-17T15:00:44.295353Z","shell.execute_reply":"2022-07-17T15:01:08.758993Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"logistic_predictions=logisticRegr.predict(test_matrix)\nconfusion_Matrix(y_test,logistic_predictions)\nprint(classification_report(y_test, logistic_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:04:14.481273Z","iopub.execute_input":"2022-07-17T15:04:14.481726Z","iopub.status.idle":"2022-07-17T15:04:14.871856Z","shell.execute_reply.started":"2022-07-17T15:04:14.481687Z","shell.execute_reply":"2022-07-17T15:04:14.870703Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"<h2>Compare the naive_model with a support vector machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nSVCClf = SVC(kernel = 'linear',gamma = 'scale', shrinking = False,)\nSVCClf.fit(train_matrix, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T14:27:33.326861Z","iopub.execute_input":"2022-07-17T14:27:33.327268Z","iopub.status.idle":"2022-07-17T14:28:58.549319Z","shell.execute_reply.started":"2022-07-17T14:27:33.327237Z","shell.execute_reply":"2022-07-17T14:28:58.548179Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"svm_predictions = SVCClf.predict(test_matrix)\nconfusion_Matrix(y_test,svm_predictions)\nprint(classification_report(y_test, svm_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:05:56.239782Z","iopub.execute_input":"2022-07-17T15:05:56.240163Z","iopub.status.idle":"2022-07-17T15:06:18.670487Z","shell.execute_reply.started":"2022-07-17T15:05:56.240132Z","shell.execute_reply":"2022-07-17T15:06:18.669378Z"},"trusted":true},"execution_count":79,"outputs":[]}]}